{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ntorch.cuda.is_available(), torch.cuda.get_device_name(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:29:37.723699Z","iopub.execute_input":"2025-07-10T17:29:37.723969Z","iopub.status.idle":"2025-07-10T17:29:39.431213Z","shell.execute_reply.started":"2025-07-10T17:29:37.723945Z","shell.execute_reply":"2025-07-10T17:29:39.430577Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"(True, 'Tesla T4')"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install torch torchvision torchaudio matplotlib opencv-python tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:29:39.431931Z","iopub.execute_input":"2025-07-10T17:29:39.432234Z","iopub.status.idle":"2025-07-10T17:29:42.650459Z","shell.execute_reply.started":"2025-07-10T17:29:39.432207Z","shell.execute_reply":"2025-07-10T17:29:42.649631Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install segmentation-models-pytorch torch torchvision albumentations opencv-python-headless matplotlib tqdm scikit-learn --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:29:42.651404Z","iopub.execute_input":"2025-07-10T17:29:42.651661Z","iopub.status.idle":"2025-07-10T17:29:45.985369Z","shell.execute_reply.started":"2025-07-10T17:29:42.651626Z","shell.execute_reply":"2025-07-10T17:29:45.984329Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install imutils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:29:45.986545Z","iopub.execute_input":"2025-07-10T17:29:45.986815Z","iopub.status.idle":"2025-07-10T17:29:48.995027Z","shell.execute_reply.started":"2025-07-10T17:29:45.986791Z","shell.execute_reply":"2025-07-10T17:29:48.994307Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: imutils in /usr/local/lib/python3.11/dist-packages (0.5.4)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install torch torchvision segmentation-models-pytorch albumentations opencv-python imutils matplotlib tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:29:48.996024Z","iopub.execute_input":"2025-07-10T17:29:48.996260Z","iopub.status.idle":"2025-07-10T17:29:52.302589Z","shell.execute_reply.started":"2025-07-10T17:29:48.996237Z","shell.execute_reply":"2025-07-10T17:29:52.301647Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.11/dist-packages (0.5.0)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: imutils in /usr/local/lib/python3.11/dist-packages (0.5.4)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.33.1)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.5.3)\nRequirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.15)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.3)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.7)\nRequirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.4.9)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport imutils\n\nIMG_SIZE = 256\n\ndef crop_img(img):\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    \n    if len(cnts) == 0:\n        return img\n    \n    c = max(cnts, key=cv2.contourArea)\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n    ADD_PIXELS = 10\n    new_img = img[max(extTop[1]-ADD_PIXELS, 0):extBot[1]+ADD_PIXELS,\n                  max(extLeft[0]-ADD_PIXELS, 0):extRight[0]+ADD_PIXELS].copy()\n    return new_img\n\ndef preprocess_dataset_and_generate_masks(source_dir, dest_dir, mask_dir):\n    os.makedirs(dest_dir, exist_ok=True)\n    os.makedirs(mask_dir, exist_ok=True)\n\n    for dir_name in os.listdir(source_dir):\n        src_class_dir = os.path.join(source_dir, dir_name)\n        dst_class_dir = os.path.join(dest_dir, dir_name)\n        msk_class_dir = os.path.join(mask_dir, dir_name)\n        os.makedirs(dst_class_dir, exist_ok=True)\n        os.makedirs(msk_class_dir, exist_ok=True)\n        \n        for img_file in tqdm(os.listdir(src_class_dir), desc=f\"Processing {dir_name}\"):\n            img_path = os.path.join(src_class_dir, img_file)\n            image = cv2.imread(img_path)\n            if image is None:\n                continue\n            new_img = crop_img(image)\n            new_img = cv2.resize(new_img, (IMG_SIZE, IMG_SIZE))\n            cv2.imwrite(os.path.join(dst_class_dir, img_file), new_img)\n\n            # Synthetic circular mask\n            mask = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n            center = (IMG_SIZE // 2, IMG_SIZE // 2)\n            radius = IMG_SIZE // 4\n            cv2.circle(mask, center, radius, 255, -1)\n            cv2.imwrite(os.path.join(msk_class_dir, img_file), mask)\n\n# Example usage for Kaggle\npreprocess_dataset_and_generate_masks(\n    source_dir=\"/kaggle/input/brain-tumor-mri-dataset/Training\",\n    dest_dir=\"/kaggle/working/cleaned/Training\",\n    mask_dir=\"/kaggle/working/cleaned_masks/Training\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:29:52.305008Z","iopub.execute_input":"2025-07-10T17:29:52.305233Z","iopub.status.idle":"2025-07-10T17:30:21.302133Z","shell.execute_reply.started":"2025-07-10T17:29:52.305212Z","shell.execute_reply":"2025-07-10T17:30:21.301239Z"}},"outputs":[{"name":"stderr","text":"Processing pituitary: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1457/1457 [00:08<00:00, 176.92it/s]\nProcessing notumor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1595/1595 [00:07<00:00, 227.25it/s]\nProcessing meningioma: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1339/1339 [00:06<00:00, 193.68it/s]\nProcessing glioma: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1321/1321 [00:06<00:00, 195.94it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import shutil\nimport random\n\nsource_dir = \"/kaggle/working/cleaned/Training\"\nmask_source_dir = \"/kaggle/working/cleaned_masks/Training\"\ntrain_split = 0.8\n\nfor cls in os.listdir(source_dir):\n    files = os.listdir(os.path.join(source_dir, cls))\n    random.shuffle(files)\n    split_idx = int(len(files) * train_split)\n    train_files = files[:split_idx]\n    test_files = files[split_idx:]\n\n    for phase, file_list in zip([\"train\", \"test\"], [train_files, test_files]):\n        for file in file_list:\n            os.makedirs(f\"/kaggle/working/split/{phase}/images/{cls}\", exist_ok=True)\n            os.makedirs(f\"/kaggle/working/split/{phase}/masks/{cls}\", exist_ok=True)\n            shutil.copy(os.path.join(source_dir, cls, file),\n                        os.path.join(f\"/kaggle/working/split/{phase}/images/{cls}\", file))\n            shutil.copy(os.path.join(mask_source_dir, cls, file),\n                        os.path.join(f\"/kaggle/working/split/{phase}/masks/{cls}\", file))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:30:21.303281Z","iopub.execute_input":"2025-07-10T17:30:21.303557Z","iopub.status.idle":"2025-07-10T17:30:23.387831Z","shell.execute_reply.started":"2025-07-10T17:30:21.303538Z","shell.execute_reply":"2025-07-10T17:30:23.387247Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset = BrainMRIDataset(\n    image_dir=\"/kaggle/working/split/train/images\",\n    mask_dir=\"/kaggle/working/split/train/masks\",\n    transform=transform\n)\n\nval_dataset = BrainMRIDataset(\n    image_dir=\"/kaggle/working/split/test/images\",\n    mask_dir=\"/kaggle/working/split/test/masks\",\n    transform=transform\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:30:23.388649Z","iopub.execute_input":"2025-07-10T17:30:23.388894Z","iopub.status.idle":"2025-07-10T17:30:23.407293Z","shell.execute_reply.started":"2025-07-10T17:30:23.388876Z","shell.execute_reply":"2025-07-10T17:30:23.406155Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_191/971537462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataset = BrainMRIDataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/split/train/images\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmask_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/split/train/masks\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'BrainMRIDataset' is not defined"],"ename":"NameError","evalue":"name 'BrainMRIDataset' is not defined","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass BrainMRIDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, transform=None):\n        self.images = []\n        for cls in os.listdir(image_dir):\n            img_path = os.path.join(image_dir, cls)\n            msk_path = os.path.join(mask_dir, cls)\n            for file in os.listdir(img_path):\n                self.images.append((os.path.join(img_path, file), os.path.join(msk_path, file)))\n        self.transform = transform\n\n    def __len__(self): return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path, mask_path = self.images[idx]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        image = cv2.resize(image, (256, 256))\n        mask = cv2.resize(mask, (256, 256))\n        mask = np.expand_dims(mask, axis=-1)\n        if self.transform:\n            augmented = self.transform(image=image, mask=mask)\n            image, mask = augmented[\"image\"], augmented[\"mask\"]\n        return image, mask.float()\n\n# Augmentations\ntransform = A.Compose([\n    A.Normalize(mean=(0.0,0.0,0.0), std=(1.0,1.0,1.0)),\n    ToTensorV2()\n])\n\ntrain_dataset = BrainMRIDataset(\n    \"/kaggle/working/split/train/images\",\n    \"/kaggle/working/split/train/masks\",\n    transform=transform\n)\nval_dataset = BrainMRIDataset(\n    \"/kaggle/working/split/test/images\",\n    \"/kaggle/working/split/test/masks\",\n    transform=transform\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:30:23.407859Z","iopub.status.idle":"2025-07-10T17:30:23.408182Z","shell.execute_reply.started":"2025-07-10T17:30:23.408061Z","shell.execute_reply":"2025-07-10T17:30:23.408076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"resnet34\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None\n).to(device)\n\nloss_fn = smp.losses.DiceLoss(mode=\"binary\")\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:30:23.409705Z","iopub.status.idle":"2025-07-10T17:30:23.410065Z","shell.execute_reply.started":"2025-07-10T17:30:23.409877Z","shell.execute_reply":"2025-07-10T17:30:23.409907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()\n    total_intersection = 0.0\n    total_union = 0.0\n\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images = images.to(device)\n            masks = masks.to(device)\n\n            preds = model(images)\n            preds = torch.sigmoid(preds)\n            preds = (preds > 0.5).float()\n\n            total_intersection += (preds * masks).sum().item()\n            total_union += (preds + masks).sum().item()\n\n    dice = (2 * total_intersection + 1e-7) / (total_union + 1e-7)\n    print(f\"üìà Validation Dice Score: {dice:.4f}\")\n    return dice\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(model, loader, epochs):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        loop = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        for images, masks in loop:\n            images, masks = images.to(device), masks.to(device)\n            preds = model(images)\n            loss = loss_fn(preds, masks)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            loop.set_postfix(loss=loss.item())\n        print(f\"Epoch {epoch+1} | Avg Loss: {total_loss/len(loader):.4f}\")\n\ntrain(model, train_loader, epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T09:00:48.524790Z","iopub.execute_input":"2025-07-10T09:00:48.525091Z","iopub.status.idle":"2025-07-10T09:33:40.927593Z","shell.execute_reply.started":"2025-07-10T09:00:48.525060Z","shell.execute_reply":"2025-07-10T09:33:40.926980Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:19<00:00,  3.58it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Avg Loss: 0.9919\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:17<00:00,  3.61it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:17<00:00,  3.62it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:17<00:00,  3.62it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:16<00:00,  3.63it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:16<00:00,  3.63it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:16<00:00,  3.63it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:16<00:00,  3.63it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:17<00:00,  3.62it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [03:16<00:00,  3.63it/s, loss=0.992]","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Avg Loss: 0.9918\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_predictions(model, dataset, num_samples=5):\n    model.eval()\n    with torch.no_grad():\n        for i in range(num_samples):\n            image, true_mask = dataset[i]\n            input_tensor = image.unsqueeze(0).to(device)\n            pred_mask = model(input_tensor)\n            pred_mask = torch.sigmoid(pred_mask).squeeze().cpu().numpy()\n            pred_mask = (pred_mask > 0.5).astype(np.uint8)\n\n            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n            axs[0].imshow(image.permute(1, 2, 0).cpu())\n            axs[0].set_title(\"Image\")\n            axs[1].imshow(true_mask.squeeze().cpu(), cmap='gray')\n            axs[1].set_title(\"True Mask\")\n            axs[2].imshow(pred_mask, cmap='gray')\n            axs[2].set_title(\"Predicted Mask\")\n            plt.show()\n\n# üîç Visualize 5 predictions\nvisualize_predictions(model, val_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:30:23.414345Z","iopub.status.idle":"2025-07-10T17:30:23.414611Z","shell.execute_reply.started":"2025-07-10T17:30:23.414491Z","shell.execute_reply":"2025-07-10T17:30:23.414505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_predictions(model, dataset, num_samples=5):\n    model.eval()\n    with torch.no_grad():\n        for i in range(num_samples):\n            image, true_mask = dataset[i]\n            input_tensor = image.unsqueeze(0).to(device)\n            pred_mask = model(input_tensor)\n            pred_mask = torch.sigmoid(pred_mask).squeeze().cpu().numpy()\n            pred_mask = (pred_mask > 0.5).astype(np.uint8)\n\n            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n            axs[0].imshow(image.permute(1, 2, 0).cpu())\n            axs[0].set_title(\"Image\")\n            axs[1].imshow(true_mask.squeeze().cpu(), cmap='gray')\n            axs[1].set_title(\"True Mask\")\n            axs[2].imshow(pred_mask, cmap='gray')\n            axs[2].set_title(\"Predicted Mask\")\n            plt.show()\n\n# Run on validation set\nvisualize_predictions(model, val_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:30:32.506953Z","iopub.execute_input":"2025-07-10T17:30:32.507285Z","iopub.status.idle":"2025-07-10T17:30:32.520661Z","shell.execute_reply.started":"2025-07-10T17:30:32.507262Z","shell.execute_reply":"2025-07-10T17:30:32.519559Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_191/3568674061.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Run on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mvisualize_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\n# DICE score function\ndef dice_score(preds, targets, threshold=0.5, eps=1e-7):\n    preds = torch.sigmoid(preds)\n    preds = (preds > threshold).float()\n\n    intersection = (preds * targets).sum(dim=(1, 2, 3))\n    union = preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3))\n    dice = (2. * intersection + eps) / (union + eps)\n    return dice.mean().item()\n\n# Evaluation loop\ndef evaluate_model(model, dataloader):\n    model.eval()\n    total_dice = 0.0\n    count = 0\n\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images = images.to(device)\n            masks = masks.to(device)\n\n            preds = model(images)\n            score = dice_score(preds, masks)\n            total_dice += score\n            count += 1\n\n    avg_dice = total_dice / count\n    print(f\"üìà Average Dice Score on Validation Set: {avg_dice:.4f}\")\n    return avg_dice\n   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T09:52:14.492302Z","iopub.execute_input":"2025-07-10T09:52:14.493024Z","iopub.status.idle":"2025-07-10T09:52:14.499379Z","shell.execute_reply.started":"2025-07-10T09:52:14.492996Z","shell.execute_reply":"2025-07-10T09:52:14.498694Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def dice_score(preds, targets, threshold=0.5, eps=1e-7):\n    preds = torch.sigmoid(preds)\n    preds = (preds > threshold).float()\n\n    targets = targets.float()\n\n    intersection = (preds * targets).sum()\n    union = preds.sum() + targets.sum()\n    dice = (2. * intersection + eps) / (union + eps)\n\n    return dice.item()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()\n    total_intersection = 0.0\n    total_union = 0.0\n\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images = images.to(device)\n            masks = masks.to(device)\n\n            preds = model(images)\n            preds = torch.sigmoid(preds)\n            preds = (preds > 0.5).float()\n\n            total_intersection += (preds * masks).sum().item()\n            total_union += (preds + masks).sum().item()\n\n    dice = (2 * total_intersection + 1e-7) / (total_union + 1e-7)\n    print(f\"üìà Corrected Average Dice Score: {dice:.4f}\")\n    return dice\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:16:55.687847Z","iopub.execute_input":"2025-07-10T10:16:55.688139Z","iopub.status.idle":"2025-07-10T10:16:55.693670Z","shell.execute_reply.started":"2025-07-10T10:16:55.688116Z","shell.execute_reply":"2025-07-10T10:16:55.692860Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"evaluate_model(model, val_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:17:04.392178Z","iopub.execute_input":"2025-07-10T10:17:04.392948Z","iopub.status.idle":"2025-07-10T10:17:53.780850Z","shell.execute_reply.started":"2025-07-10T10:17:04.392920Z","shell.execute_reply":"2025-07-10T10:17:53.780071Z"}},"outputs":[{"name":"stdout","text":"üìà Corrected Average Dice Score: 0.9207\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0.9206682850009292"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"def evaluate_metrics(model, dataloader, threshold=0.5):\n    model.eval()\n\n    TP = 0\n    FP = 0\n    FN = 0\n    total_iou = 0\n\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images, masks = images.to(device), masks.to(device)\n\n            preds = model(images)\n            preds = torch.sigmoid(preds)\n            preds = (preds > threshold).float()\n\n            TP += ((preds == 1) & (masks == 1)).sum().item()\n            FP += ((preds == 1) & (masks == 0)).sum().item()\n            FN += ((preds == 0) & (masks == 1)).sum().item()\n\n            # IoU per batch\n            intersection = (preds * masks).sum().item()\n            union = ((preds + masks) >= 1).sum().item()\n            if union > 0:\n                total_iou += intersection / union\n\n    precision = TP / (TP + FP + 1e-7)\n    recall = TP / (TP + FN + 1e-7)\n    iou = total_iou / len(dataloader)\n\n    print(f\"üìê Precision: {precision:.4f}\")\n    print(f\"üìè Recall: {recall:.4f}\")\n    print(f\"üì¶ IoU Score: {iou:.4f}\")\n\n    return precision, recall, iou\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}